#!/usr/bin/env python
# coding: utf-8

# L'optimisation bay√©sienne est une m√©thode permettant de d√©terminer les hyper-param√®tres optimaux d'un mod√®le en utilisant les outils de statistiques bay√©siennes. Leur principal int√©r√™t contrairement aux recherches par grille est d'utiliser l'information acquise au cours de l'optimisation pour d√©terminer les prochains hyper-param√®tres √† tester.
# 
# <blockquote><p>üôã <b>Ce que nous allons faire</b></p>
# <ul>
#     <li>D√©couvrir l'approche bay√©sienne d'optimisation des hyper-param√®tres</li>
#     <li>Lancer une recherche TPE sur LightGBM</li>
#     <li>Calibrer un mod√®le sur les meilleurs hyper-param√®tres</li>
# </ul>
# </blockquote>
# 
# <img src="https://media.giphy.com/media/cmqZM1lFsKHqo/giphy.gif" />

# ## Approche bay√©sienne
# 
# Dans un mod√®le, nous devons diff√©rencier deux types de param√®tres.
# 
# - En statistique param√©trique, le mod√®le est une fonction de param√®tre $\theta \in \Theta$ : les composantes de $\theta$ repr√©sentent **les param√®tres du mod√®le**. Ils sont estim√©s par des algorithmes d'optimisation num√©rique.
# - Les **hyper-param√®tres** sont des valeurs d'ajustement du mod√®le qui sont fixes et qui ne sont pas estim√©s par les algorithmes d'optimisation, mais utilis√©s par ces derniers.
# 
# Le choix des hyper-param√®tres aura donc une influence sur la fa√ßon dont le mod√®le est entra√Æn√© et automatiquement sur ses performances.
# 
# La difficult√© des hyper-param√®tres, c'est que contrairement aux param√®tres du mod√®le, il n'y a aucun moyen de savoir si un jeu d'hyper-param√®tres est optimal ou non.
# 
# Pour cela, une solution consiste √† tester plusieurs jeux d'hyper-param√®tres et de choisir celui qui maximise les performances.
# 
# Il y a autant d'entra√Ænement de mod√®le √† effectuer qu'il y a de jeux d'hyper-param√®tres. Ainsi, une question se pose : **comment d√©terminer le jeu d'hyper-param√®tre optimal le plus rapidement ?**
# 
# Jusqu'ici, la plupart des approches utilise des recherches par grille (d√©terministes ou al√©atoires) qui consiste √† tester un nombre de points finis de jeux d'hyper-param√®tres. Nous allons voir ici une autre approche, plus efficace dans certains cas.

# ### Fonction substitut
# 
# Dans l'approche bay√©sienne, nous allons ¬´ capitaliser ¬ª sur les r√©sultats obtenus aux pr√©c√©dents jeux d'hyper-param√®tres. Autrement dit, √† chaque jeu d'hyper-param√®tres, on cherche √† calculer le prochain score √† partir des hyper-param√®tres.
# 
# $$\tau(\text{Hyper-param√®tres}) \overset{\Delta}{=} \mathbb{P}(\text{Score}|\text{Hyper-param√®tres})$$
# 
# En pratique, nous ne pouvons pas calculer cette loi bay√©sienne. Pour cela, nous introduisons une fonction moins complexe mais suffisamment similaire que l'on cherchera √† optimiser. Cette fonction est appel√©e **substitut** (ou **surrogate**).
# 
# Le fait de rajouter un substitut fait que les calculs pour trouver le prochain $S_{\text{Opt}}^{(t)}$ (jeu d'hyper-param√®tres) √† tester sur un mod√®le **sont assez importants**. Mais ces temps de calculs sont compens√©s par une recherche d'un jeu d'hyper-param√®tres optimal en un nombre d'it√©rations inf√©rieurs que pour les m√©thodes de recherche par grille.
# 
# L'optimisation bay√©sienne prend tout son sens dans la recherche des hyper-param√®tres optimaux, puisque les temps de calcul de $\tau(S_{\text{Opt}}^{(t)})$ sont d√©j√† consid√©rables. En revanche, cette m√©thode n'aurait aucun int√©r√™t dans un cadre classique d'optimisation num√©rique ou de nombreuses it√©rations sont n√©cessaires pour s'approcher d'un √©ventuel extremum global.
# 
# Il existe plusieurs algorithmes bay√©siens qui permettent d'estimer un jeu d'hyper-param√®tres optimal. L'algorithme SMBO pour Sequential Model-Based Optimization est un des plus utilis√©s en Machine Learning.
# 
# ### Algorithme SMBO
# 
# L'algorithme Sequential Model-Based Optimization (SMBO) est une famille d'algorithmes bay√©siens o√π l'objectif est de maximiser $\tau$ en cherchant √† minimiser une fonction (par exemple $l$) par un mod√®le substitut (*surrogate*).
# 
# Tout d'abord, la base de connaissance $\mathcal{H}$ des hyper-param√®tres pour le substitut $\tau$ est initialis√© √† l'ensemble vide. Il est √©galement n√©cessaire de fournir un nombre d'it√©rations maximale $T$ ainsi qu'un mod√®le initial $M_0$ **pour le substitut**. La m√©thode SMBO s'ex√©cute ensuite de la fa√ßon suivante √† chaque it√©ration $t$.
# 
# 1. Estimer $S_{\text{Opt}}^{(t)}=\text{argmax}_S l(S, M_{t-1})$
# 2. Calculer le score $R$ d'un mod√®le $\hat{f}$ entra√Æn√© avec le jeu d'hyper-param√®tres $S_{\text{Opt}}^{(t)}$
# 3. Mettre √† jour la base de connaissances : $\mathcal{H}=\mathcal{H} \cup (S_{\text{Opt}}^{(t)}, R)$
# 4. Estimer un nouveau mod√®le $M_t$ pour le substitut √† partir de $\mathcal{H}$.
# 
# En pratique, les mod√®les substituts utilis√©s sont les processus Gaussiens (GP), des Random Forests (RF) ou des Tree of Parzen Estimators (TPE).
# 
# ### Fonction de s√©lection
# 
# La fonction de s√©lection (ou d'acquisition) fournit un crit√®re quantitatif dans l'algorithme SMBO : c'est elle qui permet de choisir le prochain jeu d'hyper-param√®tres √† tester (√©tape 1). Une fonction de s√©lection particuli√®rement utilis√©e est l'Expected Improvement :
# 
# <p>
# $$\text{EI}_{y^*}(u)=\int_{-\infty}^{y^*} (y^*-y)p(y|u)dy$$
# </p>
# 
# <p>
#     o√π $y^*$ est un seuil maximal et $p(y|u)$ la <b>densit√© du mod√®le substitut</b> √©valu√© en $y$ sachant $u$. L'objectif est donc de maximiser $\text{EI}_{y^*}$ sachant $u$, qui dans SMBO repr√©sentera $S_{\text{Opt}}^{(t)}$.
# </p>
# 
# <p>
#     Intuitivement, si $p(y|u) =0$ pour tout $y < y^*$, alors le jeu d'hyper-param√®tres $u := S_{\text{Opt}}^{(t)}$ est consid√©r√© comme optimal puisque aucune am√©lioration sur le score ne peut √™tre apport√©.
#     </p>
# 
# <p>
#     √Ä l'inverse, si $\text{EI}_{y^*}(u)>0$, c'est qu'il existe un meilleur jeu d'hyper-param√®tres $u$ pouvant amener √† une augmentation du score par rapport au jeu actuel. Sans une introduction d'un nombre d'it√©rations maximale, les temps de calcul pourraient √™tre bien trop √©lev√©s, non seulement parce qu'il est rare d'obtenir une valeur exacte en optimisation, mais √©galement parce que l'entra√Ænement du mod√®le $\hat{f}$ peut lui aussi d√©pendre de variations al√©atoires (propre √† ce dernier) et toujours engendrer des variations de scores pour un m√™me $u$.
#     </p>

# ## Application avec Tree of Parzen Estimators
# 
# Nous allons ici √©tudier le cas o√π le mod√®le substitut est un Tree of Parzen Estimators (TPE). L'id√©e des estimateurs Parzen est proche de l'optimisation bay√©sienne, bien qu'il y ait une diff√©rence sur le plan th√©orique.
# 
# Dans cette approche, plut√¥t que de construire un mod√®le bay√©sien dans l'√©tape 4 (et donc de mod√©liser $l(S_{\text{Opt}}^{(t)})$), on calcule directement cette quantit√© √† partir des r√®gles de calcul bay√©siennes.
# 
# $$l(S_{\text{Opt}}^{(t)})=p(y|x)=\frac{p(x|y)p(y)}{p(x)}$$
# 
# La probabilit√© d'obtenir un jeu d'hyper-param√®tres en fonction des performances du mod√®le avec $l$ est donn√© par
# 
# <p>
#     $$p(x|y)=\left\{\begin{matrix}
# l(x) & \text{si } y < y^* \\ 
# g(x) & \text{si } y \geq y^*
# \end{matrix}\right.$$
#     </p>
# 
# <p>
#     o√π $y^*$ est un seuil, similaire √† celui de $\text{EI}$, et $y$ √©tant ici la perte du mod√®le dans le cadre de l'optimisation des hyper-param√®tres. L'int√©r√™t de cette repr√©sentation est de construire deux distributions $l$ et $g$ qui correspondent aux situations o√π la perte du mod√®le est inf√©rieure au seuil $y^*$ et inversement.
#     </p>
# 
# Maintenant, reprenons le calcul de l'Expected Improvement et rempla√ßons $p(y|u)$ par le calcul bay√©sien.
# 
# <p>
#     $$
# \begin{eqnarray*}
# \text{EI}_{y^*}(u) & = & \int_{-\infty}^{y^*} (y^*-y)\frac{p(u|y)p(y)}{p(u)}dy \\
# & = & \frac{l(u)}{p(u)}  \int_{-\infty}^{y^*} (y^*-y)p(y)dy \\
# & = & \frac{l(u)}{p(u)} \left ( \gamma y^* - \int_{-\infty}^{y^*} yp(y)dy \right)
# \end{eqnarray*}
# $$
#     </p>
# 
# Or
# 
# $$p(u)=\int p(u|y)p(y)dy=\gamma l(u)+(1-\gamma)g(u)$$
# 
# donc
# 
# <p>
#     $$\text{EI}_{y^*}(u) = \frac{\gamma y^* l(u)-l(u) \int_{-\infty}^{y^*} y p(y)dy}{\gamma l(u)+(1-\gamma)g(u)} \propto \left( \gamma + \frac{g(u)}{l(u)}(1-\gamma) \right)^{-1}$$
#     </p>
# 
# <p>
#     Ce qui est int√©ressant ici, c'est que $\text{EI}_{y^*}(u)$ est proportionnel √† la quantit√© $\frac{l(u)}{g(u)}$. Et c'est exactement la logique qui se cache derri√®re $l$ et $g$, car $l$ correspond √† des situations o√π les performances du mod√®le √©taient meilleures car la perte associ√©e √©tait plus faible. En cherchant √† maximiser $\frac{l(u)}{g(u)}$, et donc l'Expected Improvement, on s'assure qu'en s√©lectionnant le prochain jeu d'hyper-param√®tres, on a plus de chances de maximiser les performances en s√©lectionnant des hyper-param√®tres dont la perte est encore plus faible.
#     </p>
# 
# Un des principaux avantages de cette m√©thode est que contrairement √† l'optimisation bay√©sienne, **il n'y a pas de mod√®le substitut √† calibrer** comme un Processus Gaussien, ce qui r√©duit les temps de calcul. On se base uniquement sur un simple calcul bay√©sien. L'appellation *Tree-structured* vient du fait que les estimateurs Parzen sont des <a href="https://fr.wikipedia.org/wiki/Estimation_par_noyau#:~:text=En%20statistique%2C%20l'estimation%20par,en%20tout%20point%20du%20support." target="_blank">estimateurs de densit√© √† noyau</a>. Ainsi, la succession chronologique du choix des hyper-param√®tres forme une structure d'arbre pour l'espace des hyper-param√®tres.
# 
# Appliquons un TPE pour le mod√®le LightGBM.

# In[ ]:


import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()

# Nous allons charger la base d'apprentissage $(X,y)$ qui sera utilis√© lors de l'optimisation bay√©sienne avec $k$-Fold, et les sous-ensembles d'entra√Ænement et de test pour calibrer le mod√®le une fois les meilleurs hyper-param√®tres obtenus.

# In[ ]:


X = pd.read_csv(os.path.expanduser("~/data/X.csv"))
y = pd.read_csv(os.path.expanduser("~/data/y.csv"))

X_train = pd.read_csv(os.path.expanduser("~/data/X_train.csv"))
X_test = pd.read_csv(os.path.expanduser("~/data/X_test.csv"))
y_train = pd.read_csv(os.path.expanduser("~/data/y_train.csv")).values.flatten()
y_test = pd.read_csv(os.path.expanduser("~/data/y_test.csv")).values.flatten()

# D√©finissons l'espace de recherche qui sera utilis√© par l'optimiseur.

# In[ ]:


from lightgbm.sklearn import LGBMClassifier
from hyperopt import hp, tpe, fmin

MODEL_SPECS = {
    "name": "LightGBM",
    "class": LGBMClassifier,
    "max_evals": 20,
    "params": {
        "learning_rate": hp.uniform("learning_rate", 0.001, 1),
        "num_iterations": hp.quniform("num_iterations", 100, 1000, 20),
        "max_depth": hp.quniform("max_depth", 4, 12, 6),
        "num_leaves": hp.quniform("num_leaves", 8, 128, 10),
        "colsample_bytree": hp.uniform("colsample_bytree", 0.3, 1),
        "subsample": hp.uniform("subsample", 0.5, 1),
        "min_child_samples": hp.quniform("min_child_samples", 1, 20, 10),
        "reg_alpha": hp.choice("reg_alpha", [0, 1e-1, 1, 2, 5, 10]),
        "reg_lambda": hp.choice("reg_lambda", [0, 1e-1, 1, 2, 5, 10]),
    },
    "override_schemas": {
        "num_leaves": int, "min_child_samples": int, "max_depth": int, "num_iterations": int
    }
}

# On pourra retrouver la <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier" target="_blank">liste des hyper-param√®tres de LightGBM</a>.
# 
# Pour faciliter la maintenance du code, nous **encapsulons** le processus d'optimisation dans une fonction `optimize_hyp` qui n√©cessite plusieurs arguments.
# 
# - `instance` est la classe h√©rit√© de `BaseEstimator` de `scikit-learn` pour instancier un mod√®le.
# - `training_set` est la base d'apprentissage $(X,y)$.
# - `search_space` est l'espace de recherche pour l'optimiseur.
# - `metric` est la m√©trique √† utiliser pour calculer le score.
# - `evals` est le nombre d'it√©rations de l'optimiseur.
# 
# <div class="alert alert-block alert-warning">
#     Dans <code>hyperopt</code>, on cherche √† minimiser une fonction objectif : il faut donc renvoyer l'inverse additif dans le cas o√π la m√©trique utilis√©e est un score.
# </div>
# 
# Dans certains cas, les hyper-param√®tres de l'espace de recherche ne sont pas toujours entiers ($10.0$ au lieu de $10$), ce qui peut g√©n√©rer des erreurs. Le champ `override_schemas` contient une liste d'hyper-param√®tres pour lesquels le conversion en nombre entier est explicite.

# In[ ]:


from sklearn.model_selection import RepeatedKFold

def optimize_hyp(instance, training_set, search_space, metric, evals=10):
    # Fonction que l'on souhaite minimiser (inverse de tau)
    def objective(params):
        for param in set(list(MODEL_SPECS["override_schemas"].keys())).intersection(set(params.keys())):
            cast_instance = MODEL_SPECS['override_schemas'][param]
            params[param] = cast_instance(params[param])
            
        # On r√©p√®te 3 fois un 5-Fold
        rep_kfold = RepeatedKFold(n_splits=4, n_repeats=1)
        scores_test = []
        for train_I, test_I in rep_kfold.split(X):
            X_fold_train = X.iloc[train_I, :]
            y_fold_train = y.iloc[train_I]
            X_fold_test = X.iloc[test_I, :]
            y_fold_test = y.iloc[test_I]

            # On entra√Æne un LightGBM avec les param√®tres par d√©faut
            model = LGBMClassifier(**params, objective="binary", verbose=-1)
            model.fit(X_fold_train, y_fold_train)

            # On calcule le score du mod√®le sur le test
            scores_test.append(
                metric(y_fold_test, model.predict(X_fold_test))
            )

        return np.mean(scores_test)

    return fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=evals)

# En appelant la fonction `optimize_hyp`, les meilleurs hyper-param√®tres vont √™tre recherch√©s puis retourn√©s une fois l'optimisation termin√©e. Nous r√©cup√©rerons les hyper-param√®tres optimaux dans la variable `optimum_params`.

# In[ ]:


from sklearn.metrics import f1_score

import warnings
warnings.filterwarnings('ignore')

optimum_params = optimize_hyp(
    MODEL_SPECS['class'],
    training_set=(X_train, y_train),
    search_space=MODEL_SPECS["params"],
    metric=lambda x, y: -f1_score(x, y), # Probl√®me de minimisation = inverse du score
    evals=MODEL_SPECS["max_evals"],
)

# Affichons les hyper-param√®tres optimaux.

# In[ ]:


optimum_params

# Maintenant que nous les connaissons, nous pouvons entra√Æner un LightGBM avec ces hyper-param√®tres.

# In[ ]:


# Chaque param√®tres dont le sch√©ma est surcharg√© est cast√© vers le bon type
for param in MODEL_SPECS['override_schemas']:
    cast_instance = MODEL_SPECS['override_schemas'][param]
    optimum_params[param] = cast_instance(optimum_params[param])

model = LGBMClassifier(**optimum_params)
model.fit(X_train, y_train)

# In[ ]:


from sklearn.metrics import recall_score, precision_score

print("F1 Score : {:2.1f}%".format(f1_score(y_test, model.predict(X_test)) * 100))
print("Precision : {:2.1f}%".format(precision_score(y_test, model.predict(X_test)) * 100))
print("Recall : {:2.1f}%".format(recall_score(y_test, model.predict(X_test)) * 100))

# Ce qui est int√©ressant ici, c'est qu'en cherchant √† maximiser le F1 score, nous avons obtenu un meilleur rappel, mais la pr√©cision est moins √©lev√©.
# 
# <div class="alert alert-block alert-danger">
#     Il ne faudrait surtout pas n'utiliser que le rappel pour optimiser le mod√®le : on obtiendrai un mod√®le avec potentiellement une mauvaise pr√©cision.
# </div>
# 
# Au final, en comparaison avec le mod√®le non optimis√©, nous n'avons que tr√®s peu gagn√© au niveau du F1 Score, mais nous avons en revanche un meilleur rappel, qui √©tait l'objectif initial puisque c'est surtout cette m√©trique qu'il faut maximiser.
# 
# Nous allons enregistrer le mod√®le au format `pkl`, que l'on r√©utilisera pour l'√©valuer et l'interpr√©ter.

# In[ ]:


import joblib

joblib.dump(model, os.path.expanduser("~/data/model.pkl"))

# ## Courbe de calibration
# 
# Les courbes de calibration permettent de comparer les proportions d'observations pr√©dites positivement et d'observations appartenant √† la classe positive √† partir du seuil $\alpha$ d√©finissant la fronti√®re du classifieur.
# 
# $$CC(\alpha)=\frac{1}{n} |\{ \hat{f}(x) \geq \alpha : x \in X \}|$$
# 
# Regardons la courbe de calibration de notre mod√®le optimis√©.

# In[ ]:


import matplotlib.ticker as mtick

from sklearn.calibration import calibration_curve

prob_pos = model.predict_proba(X_test)[:, 1]
fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)

plt.figure(figsize=(16, 10))
plt.plot([0, 1], [0, 1], "k--", label="Perfectly calibrated", alpha=0.6)
plt.plot(mean_predicted_value, fraction_of_positives, "s-", label="Model")
plt.ylabel("Fraction of positives")
plt.xlabel("Predicted probabilites")
plt.legend()
plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))
plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))
plt.title("Calibration Curve")
plt.show()

# Ce que nous voyons, c'est qu'√† partir de $40\%$, le mod√®le contient les bonnes proportions d'observations √† la fois positives et n√©gatives : il n'y a donc pas de sur-repr√©sentation d'une certaine classe lorsque les probabilit√©s pr√©dites sont sup√©rieures √† $40\%$.
# 
# En dessous de cette valeur, nous observations quelques disparit√©s, mais qui restent n√©anmoins ma√Ætris√©es sur l'ensemble des probabilit√©s. Au vu de cette courbe, nous pouvons conclure que les proportions de classes positives sont globalement respect√©es selon les probabilit√©s pr√©dites.

# ## ‚úîÔ∏è Conclusion
# 
# L'optimisation des hyper-param√®tres peut demander un effort au d√©but, mais une fois mise en place, elle constitue une v√©ritable force d'automatisation.
# 
# - Nous avons vu l'approche bay√©sienne pour l'optimisation des hyper-param√®tres d'un mod√®le de Machine Learning.
# - Nous avons optimis√© un LightGBM avec une approche Tree of Parzen Estimators.
# - Le mod√®le optimis√© a √©t√© enregistr√© au format Pickle pour √™tre r√©-utilis√© par la suite.
# 
# > ‚û°Ô∏è Derni√®re √©tape dans la construction du mod√®le : <b>validation et interpr√©tation</b>.
